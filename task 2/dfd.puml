@startuml

!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Context.puml

title DFD-схема

Person(client, "Клиенты", "Используют сервисы доменов")
Person(analyst, "Аналитики", "Строят отчеты и принимают решения")
Person(mldev, "ML/DS", "Разрабатывают и обучают модели")

System(ai, "ИИ-домен", "Сервисы на базе ИИ, хранение транзакционных данных")
System(pharma, "Фармацевтика", "Продажи, склады и учет лекарств")
System(production, "Производство техники", "Производственные данные")
System(fintech, "Финтех", "Финансовые транзакции и платежи")
System(med, "Лечебный домен", "Медицинские записи, пациенты")
System(internal, "Внутренний домен", "Кросс-запросы и интеграция между доменами")

System_Boundary(platform, "Data Platform (Open Source)") {
    System(kafka, "Kafka", "Apache Kafka", "Событийный транспорт между доменами")
    System(stream, "Stream Processor", "Apache Flink", "Обработка CDC/событий и запись в Lake/DWH")
    System(lake, "Data Lakehouse", "MinIO + Apache Iceberg", "Хранение сырых и обработанных данных")
    System(dwh, "DWH", "ClickHouse", "Аналитическая база для витрин и BI")
    System(dwh_legacy, "Legacy DWH", "MS SQL 2008", "Историческое хранилище, старые отчеты")
    System(orch, "Orchestrator", "Apache Airflow", "Оркестрация пайплайнов и ETL/ELT процессов")
    System(catalog, "Data Catalog", "DataHub", "Регистрация Data Products, управление метаданными и lineage")
}

System_Boundary(analytics, "Аналитика") {
    System(bi, "BI Portal", "Metabase / Redash", "Витрины и отчетность")
    System(ml, "ML Platform", "Jupyter + Feature Store + Flink/Spark", "Обучение и использование моделей")
    System(bi_legacy, "Legacy BI", "Power Builder", "Доступ к Legacy DWH")
}

Rel(client, ai, "Запросы/данные через API", "HTTPS REST")
Rel(client, fintech, "Финансовые операции", "HTTPS REST")
Rel(client, med, "Медицинские запросы", "HTTPS REST")

Rel(ai, kafka, "Публикует события", "Kafka Producer API")
Rel(pharma, kafka, "Публикует события", "Kafka Producer API")
Rel(production, kafka, "Публикует события", "Kafka Producer API")
Rel(fintech, kafka, "Публикует события", "Kafka Producer API")
Rel(med, kafka, "Публикует события", "Kafka Producer API")
Rel(internal, kafka, "Кросс-доменные события", "Kafka Producer API")

Rel(kafka, stream, "Стриминг событий", "Kafka Consumer API")
Rel(stream, lake, "Запись в Lakehouse", "Flink Sink / Iceberg API")
Rel(orch, lake, "Оркестрация пайплайнов", "Airflow DAGs, Python / Spark Submit")
Rel(orch, dwh, "Формирование витрин", "ClickHouse SQL / JDBC")
Rel(orch, catalog, "Передача lineage процессов", "REST API")
Rel(lake, catalog, "Регистрация датасетов", "REST API")
Rel(dwh, catalog, "Регистрация витрин", "REST API")
Rel(dwh_legacy, catalog, "Legacy lineage (read-only)", "REST API")

Rel(bi, dwh, "Чтение аналитических данных", "SQL / JDBC / BI Connector")
Rel(ml, lake, "Обучение моделей на данных", "Iceberg API / Parquet Reader")
Rel(ml, dwh, "Использование витрин для фичей", "SQL / JDBC")
Rel(bi_legacy, dwh_legacy, "Получение старых данных", "SQL / JDBC")

Rel(analyst, bi, "Строит отчеты", "BI UI")
Rel(mldev, ml, "Разрабатывает модели", "Python / Jupyter Notebook")
Rel(analyst, bi_legacy, "Представление старой отчетности", "BI UI")

@enduml
